\chapter{Model design details}
\section{Output categories}
\label{sec:Output categories}
\begin{table}[!ht]
\renewcommand{\arraystretch}{1.6}
\definecolor{caribbeangreen}{rgb}{0.0, 0.8, 0.6}
\definecolor{amber}{rgb}{1.0, 0.75, 0.0}
\definecolor{carminered}{rgb}{1.0, 0.0, 0.22}
\newcommand{\green}{\color{caribbeangreen} Green}
\newcommand{\amber}{\color{amber} Amber}
\newcommand{\red}{\color{carminered} Alert}
\begin{tabularx}{\textwidth}{|c|c|c|X|}
\hline
ID & Activity    & Alert level & Description \\ \hline
0           & Unknown     & \amber & The model cannot predict the current activity that may be a non-exam activity \\ \hline
1           & Look screen & \green & The student is looking at the screen \\ \hline
2           & Look down   & \red   & The student is looking under the table, which maybe using the phone \\ \hline
3           & Look side   & \amber & The student is looking outside the computer screen, maybe reading a book on the table \\ \hline
4           & Look back   & \amber & The student turned and is looking behind, maybe hiding something \\ \hline
5           & Leave       & \amber & The student is out of the camera range \\ \hline
6           & Speaking    & \red   & The student has obvious lip movement and may be talking to others \\ \hline
7           & Look up     & \green & The student looks up at the ceiling, may be relaxing or thinking a difficult question \\ \hline
8           & Use phone   & \red   & The student are obviously using a mobile phone \\ \hline
9           & Scratching  & \green & The student is scratching the head or face and may be thinking a difficult question \\ \hline
10          & Drinking    & \green & The student is drinking water \\ \hline
11          & Typing      & \green & The student is typing on the keyboard and answering exam questions \\ \hline
12 -- 15    & Unused      & --     & Allow for adding more activities \\ \hline
\end{tabularx}
\caption{Model output for exam activity categories}
\label{tab:Model output}
\end{table}

\section{Model detailed layers}
\label{sec:Model detailed layers}
\setlength\LTleft{-1em}
\renewcommand*{\arraystretch}{0.9}
\begin{longtable}{llll}
\toprule
                       Name &                   Type &                           Output Shape &  Param \# \\
\midrule
\multicolumn{4}{c}{Images input as the shape $(Batch, Channel, Frame, Height, Width)$} \\ \midrule
                    input\_1 &         InputLayer &                ?, 3, 16, 224, 224 &        0 \\
         tf.compat.v1.shape &         TFOpLambda &                                     5, &        0 \\
   tf.\_\_operators\_\_.getitem &    SlicingOpLambda &                                        &        0 \\
 tf.\_\_operators\_\_.getitem\_2 &    SlicingOpLambda &                                        &        0 \\
     tf.compat.v1.transpose &         TFOpLambda &                  ?, 16, 224, 224, 3 &        0 \\
           tf.math.multiply &         TFOpLambda &                                        &        0 \\
 tf.\_\_operators\_\_.getitem\_3 &    SlicingOpLambda &                                        &        0 \\
 tf.\_\_operators\_\_.getitem\_4 &    SlicingOpLambda &                                        &        0 \\
 tf.\_\_operators\_\_.getitem\_1 &    SlicingOpLambda &                                        &        0 \\
                 tf.reshape &         TFOpLambda &                 ?, ?, ?, ? &        0 \\
\midrule
\multicolumn{4}{c}{Images process to $(Batch \times Frame, Height, Width, Channel)$} \\ \midrule
            efficientnetb0 &         Functional &                        ?, 7, 7, 384 &  3759267 \\
        layer\_normalization & LayerNormalization &                        ?, 7, 7, 384 &      768 \\
       global\_max\_pooling2d & GlobalMaxPooling2D &                              ?, 384 &        0 \\
\midrule
\multicolumn{4}{c}{The CNN-based backbone(EfficientNet-B0) output extracted features} \\
\multicolumn{4}{c}{The frame indices input as the shape $(Batch, Index)$, add position embedding} \\ \midrule
              tf.reshape\_1 &         TFOpLambda &                       ?, ?, ? &        0 \\
       tf.compat.v1.shape\_1 &         TFOpLambda &                                     3, &        0 \\
 tf.\_\_operators\_\_.getitem\_5 &    SlicingOpLambda &                                        &        0 \\
 tf.\_\_operators\_\_.getitem\_7 &    SlicingOpLambda &                                        &        0 \\
            tf.broadcast\_to &         TFOpLambda &                           ?, 1, 384 &        0 \\
                  tf.concat &         TFOpLambda &                        ?, ?, 384 &        0 \\
       tf.compat.v1.shape\_2 &         TFOpLambda &                                     3, &        0 \\
 tf.\_\_operators\_\_.getitem\_8 &    SlicingOpLambda &                                        &        0 \\
           tf.math.floormod &         TFOpLambda &                                        &        0 \\
           tf.math.subtract &         TFOpLambda &                                        &        0 \\
         tf.math.floormod\_1 &         TFOpLambda &                                        &        0 \\
                    input\_2 &         InputLayer &                             ?, 16 &        0 \\
     tf.convert\_to\_tensor\_2 &         TFOpLambda &                                   2, 2 &        0 \\
         tf.compat.v1.pad\_3 &         TFOpLambda &                             ?, ? &        0 \\
 tf.\_\_operators\_\_.getitem\_6 &    SlicingOpLambda &                                        &        0 \\
                  tf.cast\_2 &         TFOpLambda &                             ?, ? &        0 \\
                   tf.zeros &         TFOpLambda &                             ?, ? &        0 \\
         tf.math.floormod\_2 &         TFOpLambda &                             ?, ? &        0 \\
           tf.compat.v1.pad &         TFOpLambda &                             ?, ? &        0 \\
       tf.convert\_to\_tensor &         TFOpLambda &                                   3, 2 &        0 \\
       tf.compat.v1.shape\_4 &         TFOpLambda &                                     2, &        0 \\
   tf.compat.v1.transpose\_1 &         TFOpLambda &                             ?, ? &        0 \\
                    tf.ones &         TFOpLambda &                             ?, ? &        0 \\
          tf.broadcast\_to\_1 &         TFOpLambda &                                ?, 1 &        0 \\
         tf.compat.v1.pad\_1 &         TFOpLambda &                       ?, ?, ? &        0 \\
tf.\_\_operators\_\_.getitem\_10 &    SlicingOpLambda &                                        &        0 \\
                    tf.cast &         TFOpLambda &                             ?, ? &        0 \\
                tf.concat\_1 &         TFOpLambda &                             ?, ? &        0 \\
         tf.math.subtract\_2 &         TFOpLambda &                                        &        0 \\
       tf.compat.v1.shape\_3 &         TFOpLambda &                                     3, &        0 \\
                   tf.where &         TFOpLambda &                             ?, ? &        0 \\
     tf.convert\_to\_tensor\_1 &         TFOpLambda &                                   2, 2 &        0 \\
                 tf.zeros\_2 &         TFOpLambda &                             ?, ? &        0 \\
 tf.\_\_operators\_\_.getitem\_9 &    SlicingOpLambda &                                        &        0 \\
         tf.compat.v1.pad\_2 &         TFOpLambda &                             ?, ? &        0 \\
         tf.compat.v1.pad\_5 &         TFOpLambda &                             ?, ? &        0 \\
         tf.math.subtract\_1 &         TFOpLambda &                                        &        0 \\
          tf.math.not\_equal &         TFOpLambda &                             ?, ? &        0 \\
   tf.compat.v1.transpose\_3 &         TFOpLambda &                             ?, ? &        0 \\
                 tf.zeros\_1 &         TFOpLambda &                             ?, ? &        0 \\
                  tf.cast\_3 &         TFOpLambda &                             ?, ? &        0 \\
                  tf.cast\_4 &         TFOpLambda &                             ?, ? &        0 \\
         tf.compat.v1.pad\_4 &         TFOpLambda &                             ?, ? &        0 \\
        tf.\_\_operators\_\_.eq &         TFOpLambda &                             ?, ? &        0 \\
                 tf.where\_1 &         TFOpLambda &                             ?, ? &        0 \\
   tf.compat.v1.transpose\_2 &         TFOpLambda &                             ?, ? &        0 \\
                 tf.where\_2 &         TFOpLambda &                             ?, ? &        0 \\
                  tf.cast\_1 &         TFOpLambda &                             ?, ? &        0 \\
\midrule
\multicolumn{4}{c}{Extracted features, attention mask, and position embedding input to the Transformer} \\
\midrule
       vtn\_longformer\_layer & VTNLongformerLayer & ?, ?, 384 & 19667712 \\
tf.\_\_operators\_\_.getitem\_11 &    SlicingOpLambda &                              ?, 384 &        0 \\
      layer\_normalization\_1 & LayerNormalization &                              ?, 384 &      768 \\
\midrule
\multicolumn{4}{c}{MLP head to output the classification} \\
\midrule
                    dense\_1 &                  Dense &                            ?, 384 &   147840 \\
                  dropout\_8 &                Dropout &                            ?, 384 &        0 \\
                    dense\_2 &                  Dense &                             ?, 16 &     6160 \\
\midrule
\multicolumn{4}{l}{Total params: 23,582,899} \\
\multicolumn{4}{l}{Trainable params: 23,542,668} \\
\multicolumn{4}{l}{Non-trainable params: 40,231} \\
\bottomrule
\end{longtable}