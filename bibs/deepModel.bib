%CNN
@article{fukushima1980neocognitron,
title={Neocognitron: A Self-organizing Neural Network Model for a Mechanism of Pattern Recognition Unaffected by Shift in Position},
author={Fukushima, Kunihiko},
journal={Biological Cybernetics},
volume={36},
number={4},
pages={193--202},
year={1980}
}

@inproceedings{zhang1988shift,
  title={Shift-invariant pattern recognition neural network and its optical architecture},
  author={Zhang, Wei and others},
  booktitle={Proceedings of annual conference of the Japan Society of Applied Physics},
  year={1988}
}

@article{lecun1989backpropagation,
  title={Backpropagation applied to handwritten zip code recognition},
  author={LeCun, Yann and Boser, Bernhard and Denker, John S and Henderson, Donnie and Howard, Richard E and Hubbard, Wayne and Jackel, Lawrence D},
  journal={Neural computation},
  volume={1},
  number={4},
  pages={541--551},
  year={1989},
  publisher={MIT Press}
}

@article{zhang1994computerized,
  title={Computerized detection of clustered microcalcifications in digital mammograms using a shift-invariant artificial neural network},
  author={Zhang, Wei and Doi, Kunio and Giger, Maryellen L and Wu, Yuzheng and Nishikawa, Robert M and Schmidt, Robert A},
  journal={Medical physics},
  volume={21},
  number={4},
  pages={517--524},
  year={1994},
  publisher={Wiley Online Library}
}

@inproceedings{lecun2010convolutional,
  title={Convolutional networks and applications in vision},
  author={LeCun, Yann and Kavukcuoglu, Koray and Farabet, Cl{\'e}ment},
  booktitle={Proceedings of 2010 IEEE international symposium on circuits and systems},
  pages={253--256},
  year={2010},
  organization={IEEE}
}

@article{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal={Advances in neural information processing systems},
  volume={25},
  pages={1097--1105},
  year={2012}
}

@article{simonyan2014very,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}

@inproceedings{he2015deep,
      title={Deep Residual Learning for Image Recognition}, 
      author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
      year={2015},
      eprint={1512.03385},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

%RRN
@techreport{jordan1986serial,
  title={Serial order: a parallel distributed processing approach. Technical report, June 1985-March 1986},
  author={Jordan, MI},
  year={1986},
  institution={California Univ., San Diego, La Jolla (USA). Inst. for Cognitive Science}
}

@article{elman1990finding,
  title={Finding structure in time},
  author={Elman, Jeffrey L},
  journal={Cognitive science},
  volume={14},
  number={2},
  pages={179--211},
  year={1990},
  publisher={Wiley Online Library}
}

@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press}
}

@article{chung2014empirical,
      title={Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling}, 
      author={Junyoung Chung and Caglar Gulcehre and KyungHyun Cho and Yoshua Bengio},
      year={2014},
      eprint={1412.3555},
      archivePrefix={arXiv},
      primaryClass={cs.NE}
}

@article{Gers2000LearningTF,
  title={Learning to Forget: Continual Prediction with LSTM},
  author={F. Gers and J. Schmidhuber and F. Cummins},
  journal={Neural Computation},
  year={2000},
  volume={12},
  pages={2451-2471}
}

@misc{phi2018illustrated,
title={Illustrated Guide to LSTM’s and GRU’s: A step by step explanation},
url={https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21}, 
journal={Towards Data Science},
author={Phi, Michael},
year={2018},
month={9}
} 

%Attention
@inproceedings{mnih2014recurrent,
  title={Recurrent models of visual attention},
  author={Mnih, Volodymyr and Heess, Nicolas and Graves, Alex and others},
  booktitle={Advances in neural information processing systems},
  pages={2204--2212},
  year={2014}
}

@article{bahdanau2016neural,
      title={Neural Machine Translation by Jointly Learning to Align and Translate}, 
      author={Dzmitry Bahdanau and Kyunghyun Cho and Yoshua Bengio},
      year={2016},
      eprint={1409.0473},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{vaswani2017attention,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2017},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@online{tensorflow2021transformer, 
    title={Transformer model for language understanding}, url={https://www.tensorflow.org/text/tutorials/transformer}, year   = "2021",
    month  = "8",
    author={TensorFlow Authors}
}
 
%Transformer
@article{devlin2019bert,
      title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}, 
      author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
      year={2019},
      eprint={1810.04805},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{girdhar2019video,
  title={Video action transformer network},
  author={Girdhar, Rohit and Carreira, Joao and Doersch, Carl and Zisserman, Andrew},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={244--253},
  year={2019}
}

@article{neimark2021video,
      title={Video Transformer Network}, 
      author={Daniel Neimark and Omri Bar and Maya Zohar and Dotan Asselmann},
      year={2021},
      eprint={2102.00719},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{arnab2021vivit,
  title={ViViT: A Video Vision Transformer}, 
  author={Anurag Arnab and Mostafa Dehghani and Georg Heigold and Chen Sun and Mario Lučić and Cordelia Schmid},
  year={2021},
  eprint={2103.15691},
  archivePrefix={arXiv},
  primaryClass={cs.CV}
}

%State-of-the-art models
@article{guo2021cmt,
      title={CMT: Convolutional Neural Networks Meet Vision Transformers}, 
      author={Jianyuan Guo and Kai Han and Han Wu and Chang Xu and Yehui Tang and Chunjing Xu and Yunhe Wang},
      year={2021},
      eprint={2107.06263},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
% @article{srinivas2021bottleneck,
%       title={Bottleneck Transformers for Visual Recognition}, 
%       author={Aravind Srinivas and Tsung-Yi Lin and Niki Parmar and Jonathon Shlens and Pieter Abbeel and Ashish Vaswani},
%       year={2021},
%       eprint={2101.11605},
%       archivePrefix={arXiv},
%       primaryClass={cs.CV}
% }

% @article{wang2021pyramid,
%       title={Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions}, 
%       author={Wenhai Wang and Enze Xie and Xiang Li and Deng-Ping Fan and Kaitao Song and Ding Liang and Tong Lu and Ping Luo and Ling Shao},
%       year={2021},
%       eprint={2102.12122},
%       archivePrefix={arXiv},
%       primaryClass={cs.CV}
% }

@article{dai2021coatnet,
      title={CoAtNet: Marrying Convolution and Attention for All Data Sizes}, 
      author={Zihang Dai and Hanxiao Liu and Quoc V. Le and Mingxing Tan},
      year={2021},
      eprint={2106.04803},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

%3DCNN
@inproceedings{tran2015learning,
  title={Learning spatiotemporal features with 3d convolutional networks},
  author={Tran, Du and Bourdev, Lubomir and Fergus, Rob and Torresani, Lorenzo and Paluri, Manohar},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={4489--4497},
  year={2015}
}

@ARTICLE{ji20123d,
  author={Ji, Shuiwang and Xu, Wei and Yang, Ming and Yu, Kai},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={3D Convolutional Neural Networks for Human Action Recognition}, 
  year={2013},
  volume={35},
  number={1},
  pages={221-231},
  doi={10.1109/TPAMI.2012.59},
  publisher={IEEE}
}

@InProceedings{baccouche2011sequential,
author="Baccouche, Moez
and Mamalet, Franck
and Wolf, Christian
and Garcia, Christophe
and Baskurt, Atilla",
title="Sequential Deep Learning for Human Action Recognition",
booktitle="Human Behavior Understanding",
year="2011",
publisher="Springer Berlin Heidelberg",
pages="29--39",
isbn="978-3-642-25446-8"
}

@article{simonyan2014twostream,
      title={Two-Stream Convolutional Networks for Action Recognition in Videos}, 
      author={Karen Simonyan and Andrew Zisserman},
      year={2014},
      eprint={1406.2199},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{feichtenhofer2016convolutional,
      title={Convolutional Two-Stream Network Fusion for Video Action Recognition}, 
      author={Christoph Feichtenhofer and Axel Pinz and Andrew Zisserman},
      year={2016},
      eprint={1604.06573},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{carreira2018quo,
      title={Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset}, 
      author={Joao Carreira and Andrew Zisserman},
      year={2018},
      eprint={1705.07750},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}